{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReservoirBuffer:\n",
    "    \"\"\"\n",
    "    Custom reservoir buffer class for batches of samples without labels, but with encoder features.\n",
    "    \"\"\"\n",
    "    def __init__(self, buffer_size, alpha_ema=1.0, device='cpu'):\n",
    "        self.buffer_size = buffer_size # Maximum size of the buffer\n",
    "        self.buffer = torch.zeros(0,1).to(device) # Buffer for input samples only (e.g. images)\n",
    "        self.buffer_features = torch.zeros(0,1).to(device) # Buffer for corresponding sample features\n",
    "        self.alpha_ema = alpha_ema # 1.0 = do not update stored features, 0.0 = substitute with new features\n",
    "        self.device = device\n",
    "\n",
    "        self.seen_samples = 0 # Samples seen so far\n",
    "\n",
    "    # Add a batch of samples and features to the buffer\n",
    "    def add(self, batch_x, batch_features):\n",
    "        assert batch_x.size(0) == batch_features.size(0)\n",
    "\n",
    "        batch_x, batch_features = batch_x.to(self.device), batch_features.to(self.device)\n",
    "\n",
    "        # Initialize empty buffers\n",
    "        if self.buffer.size(0) == 0:\n",
    "            # Extend buffer to have same dim of batch_x\n",
    "            buffer_shape = list(batch_x.size())\n",
    "            buffer_shape[0] = 0\n",
    "            self.buffer = torch.zeros(buffer_shape).to(self.device)\n",
    "\n",
    "            # Extend buffer_features to have same dim of batch_features\n",
    "            buffer_shape = list(batch_features.size())\n",
    "            buffer_shape[0] = 0\n",
    "            self.buffer_features = torch.zeros(buffer_shape).to(self.device)\n",
    "\n",
    "        batch_size = batch_x.size(0)\n",
    "\n",
    "        if self.seen_samples < self.buffer_size:\n",
    "            # Store samples until the buffer is full\n",
    "            if self.seen_samples + batch_size <= self.buffer_size:\n",
    "                # If there is enough space in the buffer, add all the samples\n",
    "                self.buffer = torch.cat((self.buffer, batch_x), dim=0)\n",
    "                self.buffer_features = torch.cat((self.buffer_features, batch_features), dim=0)\n",
    "                self.seen_samples += batch_size\n",
    "            else:\n",
    "                # If there is not enough space, add only the remaining samples\n",
    "                remaining_space = self.buffer_size - self.seen_samples\n",
    "                self.buffer = torch.cat((self.buffer, batch_x[:remaining_space]), dim=0)\n",
    "                self.buffer_features = torch.cat((self.buffer_features, batch_features[:remaining_space]), dim=0)\n",
    "                self.seen_samples += remaining_space\n",
    "        else:\n",
    "            # Replace samples with probability buffer_size/seen_samples\n",
    "            for i in range(batch_size):\n",
    "                replace_index = random.randint(0, self.seen_samples + i)\n",
    "\n",
    "                if replace_index < self.buffer_size:\n",
    "                    self.buffer[replace_index] = batch_x[i]\n",
    "                    self.buffer_features[replace_index] = batch_features[i]\n",
    "            \n",
    "            self.seen_samples += batch_size\n",
    "\n",
    "    # Sample batch_size samples from the buffer, \n",
    "    # returns samples and indices of extracted samples (for feature update)\n",
    "    def sample(self, batch_size):\n",
    "        assert batch_size <= len(self.buffer)\n",
    "\n",
    "        # Sample batch_size indices\n",
    "        indices = random.sample(range(len(self.buffer)), batch_size)\n",
    "\n",
    "        # Get sample batch from indices\n",
    "        batch_x = self.buffer[indices]\n",
    "        batch_features = self.buffer_features[indices]\n",
    "\n",
    "        return batch_x, batch_features, indices\n",
    "    \n",
    "    # Update features of buffer samples at given indices\n",
    "    def update_features(self, batch_features, indices):\n",
    "        assert batch_features.size(0) == len(indices)\n",
    "\n",
    "        batch_features = batch_features.to(self.device)\n",
    "\n",
    "        for i, idx in enumerate(indices):\n",
    "            if self.buffer_features[idx] is not None:\n",
    "                # There are already features stored for that sample\n",
    "                # EMA update of features\n",
    "                self.buffer_features[idx] = self.alpha_ema * self.buffer_features[idx] + (1 - self.alpha_ema) * batch_features[i]\n",
    "            else:\n",
    "                # No features stored yet, store newly passed features\n",
    "                self.buffer_features[idx] = batch_features[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize buffer\n",
    "buffer = ReservoirBuffer(buffer_size=2000)\n",
    "\n",
    "# create a minibatch with 20 torch images \n",
    "mb_images = torch.rand(20,3,32,32)\n",
    "\n",
    "mb_features = torch.rand(20,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.add(mb_images, mb_features)\n",
    "\n",
    "buffer.buffer.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl_ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
